{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a53b775",
   "metadata": {},
   "source": [
    "# MLPy — Sesión 4: Bucles de entrenamiento y evaluación \n",
    "\n",
    "**Objetivo:** aprender a entrenar y evaluar un modelo de manera **correcta y repetible**, distinguiendo claramente:\n",
    "\n",
    "- **épocas**, **batches** e **iteraciones**\n",
    "- **entrenamiento** vs **validación**\n",
    "- **pérdida** (se optimiza) vs **métricas** (se reportan)\n",
    "\n",
    "> Pregunta guía: ¿puedes explicar qué ocurre *exactamente* en una iteración de entrenamiento?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48975957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad700eda",
   "metadata": {},
   "source": [
    "## 1) Dataset simple (clasificación 2D)\n",
    "\n",
    "Usaremos dos nubes Gaussianas en 2D para enfocarnos en el **proceso** (no en el dataset).\n",
    "\n",
    "La meta de esta sesión no es el mejor accuracy, sino:\n",
    "- construir un **training loop** correcto\n",
    "- separar el **validation loop**\n",
    "- observar **curvas de entrenamiento** y **validación**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94841a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset sintético: dos clases separadas en 2D\n",
    "N = 800\n",
    "x0 = torch.randn(N//2, 2) + torch.tensor([-2.0, 0.0])\n",
    "x1 = torch.randn(N//2, 2) + torch.tensor([ 2.0, 0.0])\n",
    "\n",
    "X = torch.cat([x0, x1], dim=0)\n",
    "y = torch.cat([torch.zeros(N//2), torch.ones(N//2)]).long()\n",
    "\n",
    "# Mezclar el dataset\n",
    "perm = torch.randperm(N)\n",
    "X = X[perm]\n",
    "y = y[perm]\n",
    "\n",
    "# Split entrenamiento / validación\n",
    "train_frac = 0.8\n",
    "n_train = int(N * train_frac)\n",
    "\n",
    "X_train, y_train = X[:n_train], y[:n_train]\n",
    "X_val,   y_val   = X[n_train:], y[n_train:]\n",
    "\n",
    "X_train.shape, X_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472dd182",
   "metadata": {},
   "source": [
    "## 2) Épocas, batches e iteraciones\n",
    "\n",
    "Recordatorio práctico:\n",
    "\n",
    "- **Batch**: subconjunto de datos\n",
    "- **Iteración**: forward + loss + backward + update sobre *un batch*\n",
    "- **Época**: pasar por *todo* el dataset una vez\n",
    "\n",
    "Relación clave:\n",
    "- **1 batch = 1 iteración**\n",
    "- **iteraciones por época = número de batches por época**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val, y_val),     batch_size=batch_size, shuffle=False)\n",
    "\n",
    "iters_per_epoch = len(train_loader)\n",
    "iters_per_epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d44d3b1",
   "metadata": {},
   "source": [
    "## 3) Modelo, pérdida y optimizador\n",
    "\n",
    "En esta sesión usamos `nn.Module` y `torch.optim` (a diferencia de la sesión 3).\n",
    "\n",
    "**Importante:** la pérdida (loss) es el valor que optimizamos.  \n",
    "La métrica (accuracy) la usamos para interpretar resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 2)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d2606",
   "metadata": {},
   "source": [
    "## 4) Entrenamiento vs evaluación\n",
    "\n",
    "- En **entrenamiento**: `model.train()` y se calculan gradientes.\n",
    "- En **evaluación**: `model.eval()` y **no** calculamos gradientes (`torch.no_grad()`).\n",
    "\n",
    "Separar estas dos fases reduce errores y hace el proceso **diagnosticable**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd11319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_from_logits(logits: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    return (preds == y_true).float().mean().item()\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        # 1) forward\n",
    "        logits = model(xb)\n",
    "\n",
    "        # 2) loss\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        # 3) backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # 4) update\n",
    "        optimizer.step()\n",
    "\n",
    "        # métricas\n",
    "        total_loss += loss.item()\n",
    "        total_acc += accuracy_from_logits(logits, yb)\n",
    "        n_batches += 1\n",
    "\n",
    "    return total_loss / n_batches, total_acc / n_batches\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_one_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += accuracy_from_logits(logits, yb)\n",
    "        n_batches += 1\n",
    "\n",
    "    return total_loss / n_batches, total_acc / n_batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b259e85f",
   "metadata": {},
   "source": [
    "## 5) Entrenar y registrar curvas\n",
    "\n",
    "Vamos a registrar por época:\n",
    "- `train_loss`, `val_loss`\n",
    "- `train_acc`, `val_acc`\n",
    "\n",
    "La señal típica de sobreajuste es:\n",
    "- `train_loss` baja\n",
    "- `val_loss` sube (o deja de bajar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33437954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento principal\n",
    "epochs = 40\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_acc\": [],\n",
    "}\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    va_loss, va_acc = eval_one_epoch(model, val_loader, criterion)\n",
    "\n",
    "    history[\"train_loss\"].append(tr_loss)\n",
    "    history[\"val_loss\"].append(va_loss)\n",
    "    history[\"train_acc\"].append(tr_acc)\n",
    "    history[\"val_acc\"].append(va_acc)\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:02d} | train_loss={tr_loss:.4f} val_loss={va_loss:.4f} | train_acc={tr_acc:.3f} val_acc={va_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas de pérdida\n",
    "plt.figure()\n",
    "plt.plot(history[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Pérdida\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74913b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas de accuracy\n",
    "plt.figure()\n",
    "plt.plot(history[\"train_acc\"], label=\"train_acc\")\n",
    "plt.plot(history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527666ba",
   "metadata": {},
   "source": [
    "## 6) Experimento: efecto del batch size\n",
    "\n",
    "**Idea:** el gradiente con batches es una aproximación.  \n",
    "- Batch pequeño → gradiente más ruidoso → más variabilidad en la trayectoria.\n",
    "- Batch grande → gradiente más estable → menos variabilidad.\n",
    "\n",
    "Vamos a comparar dos tamaños de batch manteniendo todo lo demás constante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cff52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(batch_size: int, epochs: int = 30, lr: float = 0.1):\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(TensorDataset(X_val, y_val),     batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(2, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 2)\n",
    "    )\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    tr_losses, va_losses = [], []\n",
    "    for _ in range(epochs):\n",
    "        tr_loss, _ = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "        va_loss, _ = eval_one_epoch(model, val_loader, criterion)\n",
    "        tr_losses.append(tr_loss)\n",
    "        va_losses.append(va_loss)\n",
    "\n",
    "    return tr_losses, va_losses\n",
    "\n",
    "small_tr, small_va = run_training(batch_size=8,  epochs=30, lr=0.1)\n",
    "large_tr, large_va = run_training(batch_size=256, epochs=30, lr=0.1)\n",
    "\n",
    "len(small_tr), len(large_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ecc177",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(small_va, label=\"val_loss (batch=8)\")\n",
    "plt.plot(large_va, label=\"val_loss (batch=256)\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Pérdida de validación\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523194dd",
   "metadata": {},
   "source": [
    "## 7) Experimento: sobreajuste intencional\n",
    "\n",
    "Una forma simple de provocar sobreajuste:\n",
    "- entrenar con **muy pocos datos**\n",
    "- usar un modelo con **mucha capacidad**\n",
    "- entrenar suficientes épocas\n",
    "\n",
    "Buscamos el patrón típico:\n",
    "- `train_loss` sigue bajando\n",
    "- `val_loss` deja de bajar o empeora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subconjunto pequeño para entrenar\n",
    "torch.manual_seed(0)\n",
    "n_small = 40  # muy pocos ejemplos\n",
    "X_small, y_small = X_train[:n_small], y_train[:n_small]\n",
    "\n",
    "small_train_loader = DataLoader(TensorDataset(X_small, y_small), batch_size=8, shuffle=True)\n",
    "small_val_loader   = DataLoader(TensorDataset(X_val, y_val),     batch_size=64, shuffle=False)\n",
    "\n",
    "# Modelo más grande (más capacidad)\n",
    "big_model = nn.Sequential(\n",
    "    nn.Linear(2, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 2)\n",
    ")\n",
    "\n",
    "big_opt = torch.optim.SGD(big_model.parameters(), lr=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 120\n",
    "tr_loss_hist, va_loss_hist = [], []\n",
    "tr_acc_hist,  va_acc_hist  = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tr_loss, tr_acc = train_one_epoch(big_model, small_train_loader, big_opt, criterion)\n",
    "    va_loss, va_acc = eval_one_epoch(big_model, small_val_loader, criterion)\n",
    "\n",
    "    tr_loss_hist.append(tr_loss)\n",
    "    va_loss_hist.append(va_loss)\n",
    "    tr_acc_hist.append(tr_acc)\n",
    "    va_acc_hist.append(va_acc)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tr_loss_hist, label=\"train_loss (pocos datos)\")\n",
    "plt.plot(va_loss_hist, label=\"val_loss\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Pérdida\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b37e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(tr_acc_hist, label=\"train_acc (pocos datos)\")\n",
    "plt.plot(va_acc_hist, label=\"val_acc\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb0c77d",
   "metadata": {},
   "source": [
    "## 8) Preguntas de cierre (para discusión)\n",
    "\n",
    "1. ¿Qué diferencia conceptual hay entre **pérdida** y **accuracy**?\n",
    "\n",
    "2. ¿Por qué la validación es un **diagnóstico** y no una “meta” de entrenamiento?\n",
    "\n",
    "3. ¿Qué señales te permiten distinguir **sobreajuste** vs **subajuste** usando curvas?\n",
    "\n",
    "4. En tus resultados, ¿qué cambió al variar el **batch size**?\n",
    "\n",
    "5. ¿Qué error te parece más peligroso: olvidar `optimizer.zero_grad()` o evaluar sin `model.eval()`?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e3ff02",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
