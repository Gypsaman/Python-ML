{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d3c7422",
   "metadata": {},
   "source": [
    "# Sesión 14 — Transformers II: Arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e09ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "seq_len = 5\n",
    "d_model = 16\n",
    "num_heads = 2\n",
    "\n",
    "X = torch.randn(1, seq_len, d_model)\n",
    "\n",
    "mha = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "attn_out, attn_weights = mha(X, X, X)\n",
    "\n",
    "plt.imshow(attn_weights[0].detach())\n",
    "plt.colorbar()\n",
    "plt.title(\"Pesos de atención\")\n",
    "plt.xlabel(\"Key index\")\n",
    "plt.ylabel(\"Query index\")\n",
    "plt.show()\n",
    "\n",
    "ffn = nn.Sequential(\n",
    "    nn.Linear(d_model, 4 * d_model),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4 * d_model, d_model)\n",
    ")\n",
    "\n",
    "out = ffn(attn_out)\n",
    "out.shape\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
