{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5252e288",
   "metadata": {},
   "source": [
    "# Modelos clásicos de Machine Learning\n",
    "\n",
    "Este cuaderno muestra ejemplos simples en Python usando **scikit-learn** para:\n",
    "\n",
    "- Regresión lineal y polinomial\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Árboles de decisión\n",
    "- Random Forests\n",
    "- Support Vector Machines (SVM)\n",
    "\n",
    "Cada sección genera datos (sintéticos) y visualiza los resultados con **matplotlib**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b1ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.datasets import make_regression, make_moons, make_classification, make_circles, make_blobs\n",
    "\n",
    "np.random.seed(42)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23534db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf, X, y, title=None, h=0.02):\n",
    "    \"\"\"Plot 2D decision boundary for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : trained classifier with .predict\n",
    "    X : array-like of shape (n_samples, 2)\n",
    "    y : array-like of shape (n_samples,)\n",
    "    title : str or None\n",
    "    h : float, step size in the mesh\n",
    "    \"\"\"\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.xlabel('Característica 1')\n",
    "    plt.ylabel('Característica 2')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153858b",
   "metadata": {},
   "source": [
    "## 1. Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e637516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos de regresión lineal\n",
    "X, y = make_regression(n_samples=200, n_features=1, noise=15.0, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "print('MSE (test):', mean_squared_error(y_test, y_pred))\n",
    "print('R^2 (test):', r2_score(y_test, y_pred))\n",
    "\n",
    "# Visualización de la recta\n",
    "X_plot = np.linspace(X.min(), X.max(), 200).reshape(-1, 1)\n",
    "y_plot = lin_reg.predict(X_plot)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(X_train, y_train, alpha=0.6, label='Train')\n",
    "plt.scatter(X_test, y_test, alpha=0.8, label='Test')\n",
    "plt.plot(X_plot, y_plot, linewidth=2, label='Modelo lineal')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Regresión lineal')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae89a4a",
   "metadata": {},
   "source": [
    "## 2. Regresión polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ebb3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos no lineales (seno con ruido)\n",
    "X = np.linspace(0, 2 * np.pi, 200).reshape(-1, 1)\n",
    "y = np.sin(X[:, 0]) + 0.3 * np.random.randn(200)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "poly_model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=5, include_bias=False)),\n",
    "    ('lin_reg', LinearRegression())\n",
    "])\n",
    "\n",
    "poly_model.fit(X_train, y_train)\n",
    "y_pred = poly_model.predict(X_test)\n",
    "\n",
    "print('MSE (test):', mean_squared_error(y_test, y_pred))\n",
    "print('R^2 (test):', r2_score(y_test, y_pred))\n",
    "\n",
    "# Visualización de la curva ajustada\n",
    "X_plot = np.linspace(0, 2 * np.pi, 400).reshape(-1, 1)\n",
    "y_plot = poly_model.predict(X_plot)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(X_train, y_train, alpha=0.6, label='Train')\n",
    "plt.scatter(X_test, y_test, alpha=0.8, label='Test')\n",
    "plt.plot(X_plot, y_plot, linewidth=2, label='Modelo polinomial (grado 5)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Regresión polinomial')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15331c9d",
   "metadata": {},
   "source": [
    "## 3. K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926bb177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de clasificación no lineal (make_moons)\n",
    "X, y = make_blobs(n_samples=300, centers=4, cluster_std=1.0, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print('Accuracy (test):', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Visualizar frontera de decisión\n",
    "plot_decision_boundary(knn, X, y, title='KNN (k=5) en make_moons')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31aee5c",
   "metadata": {},
   "source": [
    "## 4. Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f404afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar los mismos datos make_moons para comparar\n",
    "X, y = make_moons(n_samples=300, noise=0.25, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred = tree_clf.predict(X_test)\n",
    "\n",
    "print('Accuracy (test):', accuracy_score(y_test, y_pred))\n",
    "\n",
    "plot_decision_boundary(tree_clf, X, y, title='Árbol de decisión (profundidad máx = 5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ac6924",
   "metadata": {},
   "source": [
    "## 5. Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de clasificación más generales\n",
    "X, y = make_classification(\n",
    "    n_samples=400,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_informative=2,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "print('Accuracy (test):', accuracy_score(y_test, y_pred))\n",
    "\n",
    "plot_decision_boundary(rf_clf, X, y, title='Random Forest (100 árboles, profundidad máx = 5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9525adb",
   "metadata": {},
   "source": [
    "## 6. Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa046989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de círculos concéntricos para mostrar kernel RBF\n",
    "X, y = make_circles(n_samples=400, factor=0.4, noise=0.1, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svm_rbf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='rbf', C=1.0, gamma='scale'))\n",
    "])\n",
    "\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "y_pred = svm_rbf.predict(X_test)\n",
    "\n",
    "print('Accuracy (test):', accuracy_score(y_test, y_pred))\n",
    "\n",
    "plot_decision_boundary(svm_rbf, X, y, title='SVM con kernel RBF en make_circles')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
